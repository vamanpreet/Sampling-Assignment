{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Balance the Dataset\n",
    "majority = data[data['Class'] == 0]\n",
    "minority = data[data['Class'] == 1]\n",
    "minority_oversampled = minority.sample(len(majority), replace=True, random_state=42)\n",
    "balanced_data = pd.concat([majority, minority_oversampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Samples\n",
    "sample_sizes = [int(len(balanced_data) * 0.2)] * 5\n",
    "samples = [balanced_data.sample(n=sample_sizes[i], random_state=i) for i in range(5)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\win 10\\AppData\\Local\\Temp\\ipykernel_13384\\4004682169.py:7: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  cluster_sample = clusters.apply(lambda x: x.sample(1)).reset_index(drop=True)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Apply Sampling Techniques\n",
    "simple_random_sample = samples[0]\n",
    "stratified_sample = train_test_split(balanced_data, stratify=balanced_data['Class'], test_size=0.2, random_state=42)[0]\n",
    "clusters = balanced_data.groupby('V1')\n",
    "cluster_sample = clusters.apply(lambda x: x.sample(1)).reset_index(drop=True)\n",
    "k = 10\n",
    "systematic_sample = balanced_data.iloc[::k, :]\n",
    "weighted_sample = balanced_data.sample(n=sample_sizes[0], weights='Amount', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sampling_methods = {\n",
    "    \"Simple Random\": simple_random_sample,\n",
    "    \"Stratified\": pd.DataFrame(stratified_sample),\n",
    "    \"Cluster\": cluster_sample,\n",
    "    \"Systematic\": systematic_sample,\n",
    "    \"Weighted\": weighted_sample\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "models = {\n",
    "    \"M1\": LogisticRegression(),\n",
    "    \"M2\": DecisionTreeClassifier(),\n",
    "    \"M3\": SVC(),\n",
    "    \"M4\": RandomForestClassifier(),\n",
    "    \"M5\": KNeighborsClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train and Evaluate Models\n",
    "accuracy_matrix = pd.DataFrame(columns=sampling_methods.keys(), index=models.keys())\n",
    "\n",
    "best_accuracy = 0\n",
    "best_combinations = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "def train_evaluate_model(model, data_sample):\n",
    "    X = data_sample.drop('Class', axis=1)\n",
    "    y = data_sample['Class']\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    return accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\win 10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\win 10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\win 10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\win 10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\win 10\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:469: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Evaluate each model on each sample\n",
    "for model_name, model in models.items():\n",
    "    for sample_name, sample_data in sampling_methods.items():\n",
    "        accuracy = train_evaluate_model(model, sample_data)\n",
    "        accuracy_matrix.loc[model_name, sample_name] = accuracy\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_combinations = [(model_name, sample_name)]\n",
    "        elif accuracy == best_accuracy:\n",
    "            best_combinations.append((model_name, sample_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy Matrix:\n",
      "   Simple Random Stratified   Cluster Systematic  Weighted\n",
      "M1      0.956522   0.923497   0.96087   0.782609  0.978261\n",
      "M2      0.978261   0.986339   0.96087   0.956522   0.98913\n",
      "M3      0.630435   0.693989  0.973913   0.586957  0.891304\n",
      "M4           1.0        1.0  0.973913        1.0   0.98913\n",
      "M5      0.923913   0.972678  0.973913   0.782609  0.956522\n"
     ]
    }
   ],
   "source": [
    "# Print Accuracy Matrix\n",
    "print(\"\\nAccuracy Matrix:\")\n",
    "print(accuracy_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best Accuracy: 1.00 achieved by:\n",
      "Model 'M4' on Sample 'Simple Random'\n",
      "Model 'M4' on Sample 'Stratified'\n",
      "Model 'M4' on Sample 'Systematic'\n"
     ]
    }
   ],
   "source": [
    "# Print Best Models and Samples\n",
    "print(f\"\\nBest Accuracy: {best_accuracy:.2f} achieved by:\")\n",
    "for model, sample in best_combinations:\n",
    "    print(f\"Model '{model}' on Sample '{sample}'\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
